{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats\n",
    "import xarray\n",
    "import numpy as np\n",
    "import xarray\n",
    "import geopandas as gpd\n",
    "import pyogrio\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "app_workspace_dir = \"../../workspaces/app_workspace\"\n",
    "# time range: 1940-01 ~ 2022-12\n",
    "all_data = xarray.open_dataset(f\"{app_workspace_dir}/combined_all_data_101.nc\")\n",
    "monthly_data = xarray.open_dataset(f\"{app_workspace_dir}/combined_monthly_data.nc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_hydrosos_streamflow_layer(year, month):\n",
    "    filtered_data = all_data[\"ds_grouped_avg\"].sel(\n",
    "        variable=\"Qout\",\n",
    "        time=(all_data[\"ds_grouped_avg\"][\"time\"].dt.month == month) &\n",
    "            (all_data[\"ds_grouped_avg\"][\"time\"].dt.year == year)\n",
    "    )\n",
    "    month_df = filtered_data.to_dataframe().reset_index()\n",
    "    average_df = monthly_data[\"monthly_average\"].to_dataframe().reset_index()\n",
    "    average_df = average_df[(average_df[\"variable\"] == \"Qout\") & (average_df[\"month\"] == month)]\n",
    "    std_df = monthly_data[\"monthly_std_dev\"].to_dataframe().reset_index()\n",
    "    std_df = std_df[(std_df[\"variable\"] == \"Qout\") & (std_df[\"month\"] == month)]\n",
    "    merged_df = month_df.merge(average_df[['rivid', 'monthly_average']], on='rivid', how='left').drop_duplicates([\"rivid\"]).reset_index()\n",
    "    merged_df = merged_df.merge(std_df[['rivid', 'monthly_std_dev']], on='rivid', how='left')\n",
    "    # Calculate Z-score for ds_grouped_avg using mean and standard deviation\n",
    "    merged_df['z_score'] = (merged_df['ds_grouped_avg'] - merged_df['monthly_average']) / merged_df['monthly_std_dev']\n",
    "\n",
    "    # Calculate exceedance probability using the cumulative distribution function (CDF)\n",
    "    merged_df['probability'] = stats.norm.cdf(merged_df['z_score'])\n",
    "    # Define the categories and corresponding colors\n",
    "    categories = [\"extremely dry\", \"dry\", \"normal range\", \"wet\", \"extremely wet\"]\n",
    "\n",
    "    # Map the exceedance_probability values to categories\n",
    "    merged_df['classification'] = np.select(\n",
    "        [merged_df['probability'] >= 0.87,\n",
    "        (merged_df['probability'] >= 0.72) & (merged_df['probability'] < 0.87),\n",
    "        (merged_df['probability'] >= 0.28) & (merged_df['probability'] < 0.72),\n",
    "        (merged_df['probability'] >= 0.13) & (merged_df['probability'] < 0.28),\n",
    "        merged_df['probability'] < 0.13],\n",
    "        categories, default=\"unknown\"\n",
    "    )\n",
    "\n",
    "    df_geometry = pyogrio.read_dataframe(f\"{app_workspace_dir}/hydrosos_streamflow_geometry.geojson\")\n",
    "    merged_df = merged_df[[\"rivid\", \"classification\"]].merge(df_geometry, how=\"inner\")\n",
    "    gdf = gpd.GeoDataFrame(merged_df)\n",
    "    gdf = gdf.sort_values(by=\"strmOrder\")\n",
    "    display(gdf)\n",
    "    gdf.to_file(f\"{app_workspace_dir}/hydrosos_streamflow_by_month/{year}-{0 if month < 10 else ''}{month}-01\", driver=\"GeoJSON\")\n",
    "    print(f\"{year}-{0 if month < 10 else ''}{month}-01 is done!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "month = 10\n",
    "year = 2010\n",
    "filtered_data = all_data[\"ds_grouped_avg\"].sel(\n",
    "        variable=\"Qout\",\n",
    "        time=(all_data[\"ds_grouped_avg\"][\"time\"].dt.month == month) &\n",
    "            (all_data[\"ds_grouped_avg\"][\"time\"].dt.year == year)\n",
    "    )\n",
    "month_df = filtered_data.to_dataframe().reset_index()\n",
    "average_df = monthly_data[\"monthly_average\"].to_dataframe().reset_index()\n",
    "average_df = average_df[(average_df[\"variable\"] == \"Qout\") & (average_df[\"month\"] == month)]\n",
    "std_df = monthly_data[\"monthly_std_dev\"].to_dataframe().reset_index()\n",
    "std_df = std_df[(std_df[\"variable\"] == \"Qout\") & (std_df[\"month\"] == month)]\n",
    "merged_df = month_df.merge(average_df[['rivid', 'monthly_average']], on='rivid', how='left').drop_duplicates([\"rivid\"]).reset_index()\n",
    "merged_df = merged_df.merge(std_df[['rivid', 'monthly_std_dev']], on='rivid', how='left')\n",
    "# Calculate Z-score for ds_grouped_avg using mean and standard deviation\n",
    "merged_df['z_score'] = (merged_df['ds_grouped_avg'] - merged_df['monthly_average']) / merged_df['monthly_std_dev']\n",
    "\n",
    "# Calculate exceedance probability using the cumulative distribution function (CDF)\n",
    "merged_df['probability'] = stats.norm.cdf(merged_df['z_score'])\n",
    "# Define the categories and corresponding colors\n",
    "categories = [\"extremely dry\", \"dry\", \"normal range\", \"wet\", \"extremely wet\"]\n",
    "\n",
    "# Map the exceedance_probability values to categories\n",
    "merged_df['classification'] = np.select(\n",
    "    [merged_df['probability'] >= 0.87,\n",
    "    (merged_df['probability'] >= 0.72) & (merged_df['probability'] < 0.87),\n",
    "    (merged_df['probability'] >= 0.28) & (merged_df['probability'] < 0.72),\n",
    "    (merged_df['probability'] >= 0.13) & (merged_df['probability'] < 0.28),\n",
    "    merged_df['probability'] < 0.13],\n",
    "    categories, default=\"unknown\"\n",
    ")\n",
    "\n",
    "df_geometry = pyogrio.read_dataframe(f\"{app_workspace_dir}/hydrosos_streamflow_geometry.geojson\")\n",
    "merged_df = merged_df[[\"rivid\", \"classification\"]].merge(df_geometry, how=\"inner\")\n",
    "gdf = gpd.GeoDataFrame(merged_df)\n",
    "gdf = gdf.sort_values(by=\"strmOrder\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = gdf.groupby(\"strmOrder\")\n",
    "geojson_lst = []\n",
    "for strmOrder, group_df in grouped:\n",
    "    geojson_lst.append(group_df.to_json())\n",
    "output_path = f\"{app_workspace_dir}/hydrosos_streamflow_by_month/{year}-{0 if month < 10 else ''}{month}-01.json\"\n",
    "with open(output_path, \"w\") as file:\n",
    "    json.dump(geojson_lst, file, indent=2, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1940-01-01 is done!\n",
      "1940-02-01 is done!\n",
      "1940-03-01 is done!\n",
      "1940-04-01 is done!\n",
      "1940-05-01 is done!\n",
      "1940-06-01 is done!\n",
      "1940-07-01 is done!\n",
      "1940-08-01 is done!\n",
      "1940-09-01 is done!\n",
      "1940-10-01 is done!\n",
      "1940-11-01 is done!\n",
      "1940-12-01 is done!\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m year \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1940\u001b[39m, \u001b[38;5;241m2023\u001b[39m):\n\u001b[1;32m      2\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m month \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m13\u001b[39m):\n\u001b[0;32m----> 3\u001b[0m         compute_hydrosos_streamflow_layer(year, month)\n",
      "Cell \u001b[0;32mIn[16], line 32\u001b[0m, in \u001b[0;36mcompute_hydrosos_streamflow_layer\u001b[0;34m(year, month)\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# Map the exceedance_probability values to categories\u001b[39;00m\n\u001b[1;32m     23\u001b[0m merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mselect(\n\u001b[1;32m     24\u001b[0m     [merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.87\u001b[39m,\n\u001b[1;32m     25\u001b[0m     (merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.72\u001b[39m) \u001b[38;5;241m&\u001b[39m (merged_df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprobability\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.87\u001b[39m),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     29\u001b[0m     categories, default\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124munknown\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     30\u001b[0m )\n\u001b[0;32m---> 32\u001b[0m df_geometry \u001b[38;5;241m=\u001b[39m pyogrio\u001b[38;5;241m.\u001b[39mread_dataframe(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mapp_workspace_dir\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/hydrosos_streamflow_geometry.geojson\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     33\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m merged_df[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrivid\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mclassification\u001b[39m\u001b[38;5;124m\"\u001b[39m]]\u001b[38;5;241m.\u001b[39mmerge(df_geometry, how\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minner\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     34\u001b[0m gdf \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(merged_df)\n",
      "File \u001b[0;32m~/miniconda3/envs/tethys/lib/python3.11/site-packages/pyogrio/geopandas.py:149\u001b[0m, in \u001b[0;36mread_dataframe\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, fids, sql, sql_dialect, fid_as_index, use_arrow, **kwargs)\u001b[0m\n\u001b[1;32m    146\u001b[0m path_or_buffer \u001b[38;5;241m=\u001b[39m _stringify_path(path_or_buffer)\n\u001b[1;32m    148\u001b[0m read_func \u001b[38;5;241m=\u001b[39m read_arrow \u001b[38;5;28;01mif\u001b[39;00m use_arrow \u001b[38;5;28;01melse\u001b[39;00m read\n\u001b[0;32m--> 149\u001b[0m result \u001b[38;5;241m=\u001b[39m read_func(\n\u001b[1;32m    150\u001b[0m     path_or_buffer,\n\u001b[1;32m    151\u001b[0m     layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[1;32m    152\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    153\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    154\u001b[0m     read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[1;32m    155\u001b[0m     force_2d\u001b[38;5;241m=\u001b[39mforce_2d,\n\u001b[1;32m    156\u001b[0m     skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[1;32m    157\u001b[0m     max_features\u001b[38;5;241m=\u001b[39mmax_features,\n\u001b[1;32m    158\u001b[0m     where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    159\u001b[0m     bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[1;32m    160\u001b[0m     fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[1;32m    161\u001b[0m     sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[1;32m    162\u001b[0m     sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[1;32m    163\u001b[0m     return_fids\u001b[38;5;241m=\u001b[39mfid_as_index,\n\u001b[1;32m    164\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    165\u001b[0m )\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_arrow:\n\u001b[1;32m    168\u001b[0m     meta, table \u001b[38;5;241m=\u001b[39m result\n",
      "File \u001b[0;32m~/miniconda3/envs/tethys/lib/python3.11/site-packages/pyogrio/raw.py:137\u001b[0m, in \u001b[0;36mread\u001b[0;34m(path_or_buffer, layer, encoding, columns, read_geometry, force_2d, skip_features, max_features, where, bbox, fids, sql, sql_dialect, return_fids, **kwargs)\u001b[0m\n\u001b[1;32m    134\u001b[0m dataset_kwargs \u001b[38;5;241m=\u001b[39m _preprocess_options_key_value(kwargs) \u001b[38;5;28;01mif\u001b[39;00m kwargs \u001b[38;5;28;01melse\u001b[39;00m {}\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 137\u001b[0m     result \u001b[38;5;241m=\u001b[39m ogr_read(\n\u001b[1;32m    138\u001b[0m         path,\n\u001b[1;32m    139\u001b[0m         layer\u001b[38;5;241m=\u001b[39mlayer,\n\u001b[1;32m    140\u001b[0m         encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[1;32m    141\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[1;32m    142\u001b[0m         read_geometry\u001b[38;5;241m=\u001b[39mread_geometry,\n\u001b[1;32m    143\u001b[0m         force_2d\u001b[38;5;241m=\u001b[39mforce_2d,\n\u001b[1;32m    144\u001b[0m         skip_features\u001b[38;5;241m=\u001b[39mskip_features,\n\u001b[1;32m    145\u001b[0m         max_features\u001b[38;5;241m=\u001b[39mmax_features \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m0\u001b[39m,\n\u001b[1;32m    146\u001b[0m         where\u001b[38;5;241m=\u001b[39mwhere,\n\u001b[1;32m    147\u001b[0m         bbox\u001b[38;5;241m=\u001b[39mbbox,\n\u001b[1;32m    148\u001b[0m         fids\u001b[38;5;241m=\u001b[39mfids,\n\u001b[1;32m    149\u001b[0m         sql\u001b[38;5;241m=\u001b[39msql,\n\u001b[1;32m    150\u001b[0m         sql_dialect\u001b[38;5;241m=\u001b[39msql_dialect,\n\u001b[1;32m    151\u001b[0m         return_fids\u001b[38;5;241m=\u001b[39mreturn_fids,\n\u001b[1;32m    152\u001b[0m         dataset_kwargs\u001b[38;5;241m=\u001b[39mdataset_kwargs,\n\u001b[1;32m    153\u001b[0m     )\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for year in range(1940, 2023):\n",
    "    for month in range(1, 13):\n",
    "        compute_hydrosos_streamflow_layer(year, month)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tethys",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
